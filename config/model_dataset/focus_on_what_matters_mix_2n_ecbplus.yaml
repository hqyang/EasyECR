common:
  config_name: focus_on_what_matters_mix_2n_ecbplus
  base_dir:  /home/nobody/code/EasyECR
  mode: evaluate
  model_dir: /shared_space/nobody/ecr-code/${common.config_name}_model
  cache_dir: /home/nobody/code/ecr-code/${common.config_name}_cache
  log_dir: /home/nobody/code/ecr-code/${common.config_name}_log

ecr_data:
  dataset_name: ecbplus
  total_path: /data/dev/ecr-data/ECB+_LREC2014
  train_path:
  dev_path:
  test_path:

DocTagger:
  output_tag: doc_predicted_topic

EcrFramework1:
  output_tag: event_id_predict_ecr_framework1
  parameters:
    evaluate_topic: basic_topic
    predict_topic: basic_topic
    main_metric: CoNLL
    ecr_model:
      parameters:
        train_topic: doc_topic
        predict_topic: doc_topic
        sent_sim_threshold: 0.05
      output_tag: distance_lemma
    ecr_model_output_tag: distance_lemma
    cluster_model:
      parameters:
        distance_threshold: 0.5
        best_distance: 0.5
    evaluator:
      parameters:
        average_over_topic: False
        metric_names: ['mentions', 'muc', 'bcub', 'ceafe', 'lea']
        keep_singletons: True


EcrFramework2:
  output_tag: event_id_pred_ecr_framework2
  parameters:
    evaluate_topic: event_id_predict_ecr_framework1
    predict_topic: doc_topic
    main_metric: CoNLL
    ecr_model:
      output_tag: distance_ecr_framework2
      parameters:
        common:
          mode: ${common.mode}
          train_topic: doc_topic
          predict_topic: doc_topic
          evaluate_topic: doc_topic
          model_dir: ${common.model_dir}/ecr_framework2/
          best_model_file_name: best.ckpt
          framework1_tag: distance_lemma
        module:
          transformer_model: roberta-large
          no_decay_params: []
          weight_decay: 0.0
          optimizer: adam
          learning_rate: 0.000005
          num_warmup_steps: 0
          num_training_steps: 300000
          model_checkpoint: ${EcrFramework2.parameters.ecr_model.parameters.common.model_dir}/best.ckpt
        dataset:
        dataloader:
          train_batch_size: 10
          evaluate_batch_size: 128
          predict_batch_size: 128
          num_workers: 1
        trainer_parameters:
          accelerator: gpu
          accumulate_grad_batches: 20
          gradient_clip_val: 10.0
          check_val_every_n_epoch: 1
          max_epochs: 16
          default_root_dir: ${common.log_dir}/pl
    ecr_model_output_tag: distance_ecr_framework2
    cluster_model:
      model_name: EcrConnectedComponent
      parameters:
        distance_threshold: [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]
        best_distance:
    evaluator:
      parameters:
        average_over_topic: False
        metric_names: ['mentions', 'muc', 'bcub', 'ceafe', 'lea']
        keep_singletons: True
