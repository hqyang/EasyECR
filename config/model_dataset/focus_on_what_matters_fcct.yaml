common:
  config_name: focus_on_what_matters_fcct
  base_dir:  /home/nobody/code/EasyECR
  mode: evaluate
  model_dir: /shared_space/nobody/ecr-code/${common.config_name}_model
  cache_dir: /home/nobody/code/ecr-code/${common.config_name}_cache
  log_dir: /home/nobody/code/ecr-code/${common.config_name}_log

ecr_data:
  dataset_name: fcct
  total_path:
  train_path: /data/dev/ecr-data/fcc/2020-10-05_FCC-T/train
  dev_path: /data/dev/ecr-data/fcc/2020-10-05_FCC-T/dev
  test_path: /data/dev/ecr-data/fcc/2020-10-05_FCC-T/test

DocTagger:
  output_tag: doc_predicted_topic

EcrFramework1:
  output_tag: event_id_pred_ecr_framework1
  parameters:
    evaluate_topic: doc_topic
    predict_topic: doc_topic
    main_metric: CoNLL
    ecr_model:
      output_tag: repr_ecr_framework1
      parameters:
        common:
          mode: ${common.mode}
          train_topic: doc_topic
          predict_topic: doc_topic
          evaluate_topic: doc_topic
          model_dir: ${common.model_dir}/ecr_framework1/
          best_model_file_name: best.ckpt
        module:
          transformer_model: roberta-large
          no_decay_params: []
          weight_decay: 0.01
          optimizer: adam
          learning_rate: 0.00001
          num_warmup_steps: 0
          num_training_steps: 300000
          model_checkpoint: ${EcrFramework1.parameters.ecr_model.parameters.common.model_dir}/best.ckpt
        dataset:
        dataloader:
          train_batch_size: 10
          evaluate_batch_size: 32
          predict_batch_size: 32
          num_workers: 1
        trainer_parameters:
          accelerator: gpu
          accumulate_grad_batches: 16
          gradient_clip_val: 10.0
          check_val_every_n_epoch: 1
          max_epochs: 16
          default_root_dir: ${common.log_dir}/pl
    ecr_model_output_tag: repr_ecr_framework1
    cluster_model:
      model_name: EcrConnectedComponent
      parameters:
        distance_threshold: [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]
        best_distance:
    evaluator:
      parameters:
        average_over_topic: False
        metric_names: ['mentions', 'muc', 'bcub', 'ceafe', 'lea']
        keep_singletons: True

embedding_distance:
  name: EmbeddingDistance
  parameters:
    train_topic: doc_topic
    predict_topic: doc_topic
    repr_tag: repr_ecr_framework1
  output_tag: embedding_distance


EcrFramework2:
  output_tag: event_id_pred_ecr_framework2
  parameters:
    evaluate_topic: doc_topic
    predict_topic: doc_topic
    main_metric: CoNLL
    ecr_model:
      output_tag: distance_ecr_framework2
      parameters:
        common:
          mode: ${common.mode}
          train_topic: doc_topic
          predict_topic: doc_topic
          evaluate_topic: doc_topic
          model_dir: ${common.model_dir}/ecr_framework2/
          best_model_file_name: best.ckpt
          framework1_tag: embedding_distance
        module:
          transformer_model: roberta-large
          no_decay_params: []
          weight_decay: 0.01
          optimizer: adam
          learning_rate: 0.00001
          num_warmup_steps: 0
          num_training_steps: 300000
          model_checkpoint: ${EcrFramework2.parameters.ecr_model.parameters.common.model_dir}/best.ckpt
        dataset:
        dataloader:
          train_batch_size: 16
          evaluate_batch_size: 128
          predict_batch_size: 128
          num_workers: 1
        trainer_parameters:
          accelerator: gpu
          accumulate_grad_batches: 20
          gradient_clip_val: 10.0
          check_val_every_n_epoch: 1
          max_epochs: 20
          default_root_dir: ${common.log_dir}/pl
    ecr_model_output_tag: distance_ecr_framework2
    cluster_model:
      model_name: EcrConnectedComponent
      parameters:
        distance_threshold: [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]
        best_distance:
    evaluator:
      parameters:
        average_over_topic: False
        metric_names: ['mentions', 'muc', 'bcub', 'ceafe', 'lea']
        keep_singletons: False
