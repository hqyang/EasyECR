common:
  config_name: crl_ecbplus
  base_dir: /home/nobody/code/EasyECR
  mode: evaluate
  model_dir: /home/nobody/code/ecr-code/${common.config_name}_model
  cache_dir: /home/nobody/code/ecr-code/${common.config_name}_cache
  log_dir: /home/nobody/code/ecr-code/${common.config_name}_log

ecr_data:
  dataset_name: ecbplus
  total_path: /data/dev/ecr-data/ECB+_LREC2014
  train_path:
  dev_path:
  test_path:

EcrFramework1:
  output_tag: event_id_pred_ecr_framework1
  parameters:
    evaluate_topic: doc_topic
    predict_topic: doc_topic
    main_metric: CoNLL
    ecr_model:
      output_tag: repr_ecr_framework1
      parameters:
        common:
          mode: ${common.mode}
          train_topic: doc_topic
          predict_topic: doc_topic
          evaluate_topic: doc_topic
          model_dir: ${common.model_dir}/ecr_framework1/
          best_model_file_name: best.ckpt
        module:
          transformer_model: roberta-base
          no_decay_params: []
          weight_decay: 0.0
          optimizer: adam
          learning_rate: 0.000001
          num_warmup_steps: 0
          num_training_steps: 300000
          model_checkpoint: ${EcrFramework1.parameters.ecr_model.parameters.common.model_dir}/best.ckpt
        dataset:
        dataloader:
          train_batch_size: 16
          evaluate_batch_size: 64
          predict_batch_size: 64
          num_workers: 1
        trainer_parameters:
          accelerator: gpu
          accumulate_grad_batches: 16
          gradient_clip_val: 10.0
          check_val_every_n_epoch: 1
          max_epochs: 20
          default_root_dir: ${common.log_dir}/pl
    ecr_model_output_tag: repr_ecr_framework1
    cluster_model:
      model_name: EcrConnectedComponent
      parameters:
        distance_threshold: [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]
        best_distance:
    evaluator:
      parameters:
        average_over_topic: False
        metric_names: ['mentions', 'muc', 'bcub', 'ceafe', 'lea']
        keep_singletons: True

text_encoder_repr:
  name: SgptTextEncoderRepr
  parameters:
    version: 125m
    device: 0
  output_tag: text_encoder_repr

embedding_distance:
  name: EmbeddingDistance
  parameters:
    train_topic: doc_topic
    predict_topic: doc_topic
    repr_tag: text_encoder_repr
  output_tag: embedding_distance

EcrFramework2:
  output_tag: event_id_pred_ecr_framework1
  parameters:
    evaluate_topic: doc_topic
    predict_topic: doc_topic
    main_metric: CoNLL
    ecr_model:
      output_tag: repr_ecr_framework1
      parameters:
        common:
          mode: ${common.mode}
          train_topic: doc_topic
          predict_topic: doc_subtopic
          evaluate_topic: doc_topic
          model_dir: ${common.model_dir}/ecr_framework1/
          best_model_file_name: best.ckpt
        module:
          transformer_model: roberta-base
          optimizer: adam
          learning_rate: 1e-6
          num_warmup_steps: 0
          num_training_steps: 300000
          model_checkpoint: ${EcrFramework1.parameters.ecr_model.parameters.common.model_dir}/best.ckpt
        dataset:
        dataloader:
          train_batch_size: 16
          evaluate_batch_size: 64
          predict_batch_size: 64
          num_workers: 1
        trainer_parameters:
          accelerator: gpu
          gradient_clip_val: 10.0
          check_val_every_n_epoch: 1
          max_epochs: 20
          default_root_dir: ${common.log_dir}/pl
    ecr_model_output_tag: repr_ecr_framework1
    cluster_model:
      model_name: EcrAgglomerativeClustering
      parameters:
        distance_threshold: [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]
        best_distance:
    evaluator:
      parameters:
        average_over_topic: False
        metric_names: ['mentions', 'muc', 'bcub', 'ceafe', 'lea']
        keep_singletons: False

